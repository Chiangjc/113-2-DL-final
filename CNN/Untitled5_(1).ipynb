{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTh0_NnmrSS5",
        "outputId": "9b84478e-7c88-413b-be2d-9f252ee67ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/dataset_all.zip'\n",
        "extract_path = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "PnERq2mvsYzC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# åŸå§‹è·¯å¾‘\n",
        "base_input_path = '/content/data/dataset_all'  # æ”¹æˆä½ è§£å£“ç¸®å¾Œçš„æ ¹ç›®éŒ„\n",
        "base_output_path = '/content/image_classification_data'\n",
        "\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "for split in splits:\n",
        "    image_dir = os.path.join(base_input_path, split, 'images')\n",
        "    label_dir = os.path.join(base_input_path, split, 'labels')\n",
        "    output_split_dir = os.path.join(base_output_path, split)\n",
        "\n",
        "    os.makedirs(output_split_dir, exist_ok=True)\n",
        "\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith('.txt'):\n",
        "            continue\n",
        "\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if not lines:\n",
        "                continue\n",
        "            class_id = lines[0].split()[0]  # YOLO æ ¼å¼çš„ç¬¬ä¸€å€‹æ¬„ä½æ˜¯é¡åˆ¥\n",
        "\n",
        "        image_name = label_file.replace('.txt', '.jpg')  # æˆ– .pngï¼Œæ ¹æ“šä½ çš„æª”åæ±ºå®š\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            continue\n",
        "\n",
        "        class_dir = os.path.join(output_split_dir, class_id)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        shutil.copy(image_path, os.path.join(class_dir, image_name))\n"
      ],
      "metadata": {
        "id": "5uolasCvtC_t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def create_multilabel_csv(image_dir, label_dir, output_csv):\n",
        "    data = []\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith('.txt'):\n",
        "            continue\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if len(lines) == 0:\n",
        "                continue\n",
        "            # æ“·å–æ¯ä¸€è¡Œçš„ class_idï¼Œæ”¾é€²é›†åˆé¿å…é‡è¤‡\n",
        "            classes = set()\n",
        "            for line in lines:\n",
        "                class_id = line.split()[0]\n",
        "                classes.add(class_id)\n",
        "        image_name = label_file.replace('.txt', '.jpg')  # æˆ–æ”¹æˆä½ ç”¨çš„å‰¯æª”å\n",
        "        data.append({'image_name': image_name, 'labels': ' '.join(sorted(classes))})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Saved multilabel CSV to {output_csv}\")\n",
        "\n",
        "# ç¯„ä¾‹è·¯å¾‘ï¼Œæ”¹æˆä½ å¯¦éš›è·¯å¾‘\n",
        "train_img_dir = '/content/data/dataset_all/train/images'\n",
        "train_label_dir = '/content/data/dataset_all/train/labels'\n",
        "val_img_dir = '/content/data/dataset_all/val/images'\n",
        "val_label_dir = '/content/data/dataset_all/val/labels'\n",
        "\n",
        "# ç”¢ç”ŸCSV\n",
        "create_multilabel_csv(train_img_dir, train_label_dir, '/content/image_classification_data/train_labels.csv')\n",
        "create_multilabel_csv(val_img_dir, val_label_dir, '/content/image_classification_data/val_labels.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy9WtkDT7Ssp",
        "outputId": "a68686d6-6cdd-4352-dab8-9cf11bcede98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved multilabel CSV to /content/image_classification_data/train_labels.csv\n",
            "Saved multilabel CSV to /content/image_classification_data/val_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. è‡ªè¨‚ Dataset\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_path, img_dir, num_classes, transform=None):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.img_dir = img_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['image_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        labels = row['labels'].split()  # å‡è¨­ labels æ˜¯ä»¥ç©ºç™½éš”é–‹çš„å¤šæ¨™ç±¤å­—ä¸²\n",
        "        multi_hot = torch.zeros(self.num_classes, dtype=torch.float32)\n",
        "        for l in labels:\n",
        "            multi_hot[int(l)] = 1.0\n",
        "\n",
        "        return image, multi_hot\n",
        "\n",
        "# 2. è¨­å®šåƒæ•¸\n",
        "num_classes = 7  # ä½ çš„é¡åˆ¥æ•¸é‡ï¼Œè«‹ä¿®æ”¹\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "train_csv = '/content/image_classification_data/train_labels.csv'\n",
        "val_csv = '/content/image_classification_data/val_labels.csv'\n",
        "train_dir = '/content/data/dataset_all/train/images'\n",
        "val_dir = '/content/data/dataset_all/val/images'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],  # é€™æ˜¯ResNetå¸¸ç”¨çš„ImageNetæ­£è¦åŒ–\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 3. å»ºç«‹ Dataset èˆ‡ DataLoader\n",
        "train_dataset = MultiLabelDataset(train_csv, train_dir, num_classes, transform=transform)\n",
        "val_dataset = MultiLabelDataset(val_csv, val_dir, num_classes, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# 4. å»ºç«‹æ¨¡å‹\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        # ğŸ” å‹•æ…‹æ¨ç®— Flatten size\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
        "            dummy_output = self.features(dummy_input)\n",
        "            self.flattened_size = dummy_output.view(1, -1).shape[1]  # e.g. 128 * 28 * 28\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.flattened_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "\n",
        "# 5. æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# 6. è¨“ç·´èˆ‡é©—è­‰å‡½å¼\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    return running_loss / len(train_dataset)\n",
        "\n",
        "def validate():\n",
        "    model.eval()\n",
        "    threshold = 0.5\n",
        "    correct_per_class = torch.zeros(num_classes)\n",
        "    total_per_class = torch.zeros(num_classes)\n",
        "\n",
        "    total_correct = 0\n",
        "    total_preds = 0\n",
        "    total_labels = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = (torch.sigmoid(outputs) > threshold).float()\n",
        "\n",
        "            # per-class æ­£ç¢ºæ•¸èˆ‡ç¸½æ•¸\n",
        "            correct_per_class += ((preds == labels) * labels).sum(dim=0).cpu()\n",
        "            total_per_class += labels.sum(dim=0).cpu()\n",
        "\n",
        "            # micro F1 æ‰€éœ€çš„çµ±è¨ˆ\n",
        "            total_correct += (preds * labels).sum().item()\n",
        "            total_preds += preds.sum().item()\n",
        "            total_labels += labels.sum().item()\n",
        "\n",
        "    # per-label accuracy\n",
        "    per_label_accuracy = (correct_per_class / (total_per_class + 1e-8)).mean().item()\n",
        "\n",
        "    # micro-average F1\n",
        "    precision = total_correct / (total_preds + 1e-8)\n",
        "    recall = total_correct / (total_labels + 1e-8)\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.0\n",
        "\n",
        "    return per_label_accuracy, precision, recall, f1\n",
        "\n",
        "# 7. ä¸»è¨“ç·´è¿´åœˆ\n",
        "best_accuracy = 0.0  # åˆå§‹åŒ–æœ€ä½³ accuracy\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_one_epoch()\n",
        "    per_label_accuracy, precision, recall, f1 = validate()\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Per-label Accuracy={per_label_accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    # åªä¿ç•™æœ€ä½³æ¨¡å‹\n",
        "    if per_label_accuracy > best_accuracy:\n",
        "        best_accuracy = per_label_accuracy\n",
        "        save_path = \"best_model.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Best model updated and saved with accuracy: {best_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWYOdAe56y0Q",
        "outputId": "561298c9-1ff9-4098-d8d5-bbd6ea00b58a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=0.5601, Per-label Accuracy=0.0880, Precision=0.4937, Recall=0.1193, F1=0.1921\n",
            "Best model updated and saved with accuracy: 0.0880\n",
            "Epoch 2: Train Loss=0.3606, Per-label Accuracy=0.2362, Precision=0.6467, Recall=0.3303, F1=0.4372\n",
            "Best model updated and saved with accuracy: 0.2362\n",
            "Epoch 3: Train Loss=0.2964, Per-label Accuracy=0.2950, Precision=0.7562, Recall=0.3700, F1=0.4969\n",
            "Best model updated and saved with accuracy: 0.2950\n",
            "Epoch 4: Train Loss=0.2460, Per-label Accuracy=0.4694, Precision=0.7733, Recall=0.5321, F1=0.6304\n",
            "Best model updated and saved with accuracy: 0.4694\n",
            "Epoch 5: Train Loss=0.1867, Per-label Accuracy=0.5445, Precision=0.8032, Recall=0.6116, F1=0.6944\n",
            "Best model updated and saved with accuracy: 0.5445\n",
            "Epoch 6: Train Loss=0.1346, Per-label Accuracy=0.6644, Precision=0.8156, Recall=0.7034, F1=0.7553\n",
            "Best model updated and saved with accuracy: 0.6644\n",
            "Epoch 7: Train Loss=0.1031, Per-label Accuracy=0.6611, Precision=0.8221, Recall=0.7064, F1=0.7599\n",
            "Epoch 8: Train Loss=0.0706, Per-label Accuracy=0.7015, Precision=0.8351, Recall=0.7278, F1=0.7778\n",
            "Best model updated and saved with accuracy: 0.7015\n",
            "Epoch 9: Train Loss=0.0594, Per-label Accuracy=0.7185, Precision=0.8311, Recall=0.7523, F1=0.7897\n",
            "Best model updated and saved with accuracy: 0.7185\n",
            "Epoch 10: Train Loss=0.0417, Per-label Accuracy=0.6762, Precision=0.8246, Recall=0.7187, F1=0.7680\n",
            "Epoch 11: Train Loss=0.0329, Per-label Accuracy=0.7086, Precision=0.8357, Recall=0.7309, F1=0.7798\n",
            "Epoch 12: Train Loss=0.0345, Per-label Accuracy=0.6538, Precision=0.8156, Recall=0.7034, F1=0.7553\n",
            "Epoch 13: Train Loss=0.0289, Per-label Accuracy=0.6941, Precision=0.8375, Recall=0.7248, F1=0.7770\n",
            "Epoch 14: Train Loss=0.0193, Per-label Accuracy=0.7119, Precision=0.8243, Recall=0.7462, F1=0.7833\n",
            "Epoch 15: Train Loss=0.0177, Per-label Accuracy=0.7062, Precision=0.7980, Recall=0.7492, F1=0.7729\n",
            "Epoch 16: Train Loss=0.0148, Per-label Accuracy=0.7032, Precision=0.8094, Recall=0.7401, F1=0.7732\n",
            "Epoch 17: Train Loss=0.0155, Per-label Accuracy=0.7116, Precision=0.8288, Recall=0.7401, F1=0.7819\n",
            "Epoch 18: Train Loss=0.0138, Per-label Accuracy=0.6991, Precision=0.8417, Recall=0.7156, F1=0.7736\n",
            "Epoch 19: Train Loss=0.0185, Per-label Accuracy=0.7098, Precision=0.8556, Recall=0.7248, F1=0.7848\n",
            "Epoch 20: Train Loss=0.0123, Per-label Accuracy=0.7087, Precision=0.8587, Recall=0.7431, F1=0.7967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å„²å­˜æ¨¡å‹\n",
        "torch.save(model.state_dict(), '20epochs_model_weights.pth')\n"
      ],
      "metadata": {
        "id": "RKRjgtW5Am5x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "\n",
        "# === 1. å»ºç«‹ test CSVï¼ˆå¾ label æª”æ¨å¾— image åï¼‰===\n",
        "def create_multilabel_csv(image_dir, label_dir, output_csv):\n",
        "    data = []\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith('.txt'):\n",
        "            continue\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if len(lines) == 0:\n",
        "                continue\n",
        "            classes = set()\n",
        "            for line in lines:\n",
        "                class_id = line.split()[0]\n",
        "                classes.add(class_id)\n",
        "        image_name = label_file.replace('.txt', '.jpg')  # ç¢ºèªå‰¯æª”åæ˜¯å¦æ­£ç¢º\n",
        "        data.append({'image_name': image_name, 'labels': ' '.join(sorted(classes))})\n",
        "\n",
        "    pd.DataFrame(data).to_csv(output_csv, index=False)\n",
        "    print(f\"âœ… Test CSV saved to {output_csv}\")\n",
        "\n",
        "# === 2. è‡ªè¨‚ Dataset é¡ ===\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_path, img_dir, num_classes, transform=None):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.img_dir = img_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['image_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        labels = row['labels'].split()\n",
        "        multi_hot = torch.zeros(self.num_classes, dtype=torch.float32)\n",
        "        for l in labels:\n",
        "            multi_hot[int(l)] = 1.0\n",
        "\n",
        "        return image, multi_hot, row['image_name']\n",
        "\n",
        "# === 3. è³‡æ–™èˆ‡æ¨¡å‹è¨­å®š ===\n",
        "num_classes = 7\n",
        "test_img_dir = '/content/data/dataset_all/test/images'\n",
        "test_label_dir = '/content/data/dataset_all/test/labels'\n",
        "test_csv_path = '/content/image_classification_data/test_labels.csv'\n",
        "create_multilabel_csv(test_img_dir, test_label_dir, test_csv_path)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === 4. è¼‰å…¥æ¨¡å‹ ===\n",
        "model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "# === 5. æ¸¬è©¦èˆ‡è©•ä¼° ===\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "test_dataset = MultiLabelDataset(test_csv_path, test_img_dir, num_classes, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "threshold = 0.5\n",
        "results = []\n",
        "\n",
        "correct_per_class = torch.zeros(num_classes)\n",
        "total_per_class = torch.zeros(num_classes)\n",
        "\n",
        "# Micro-averaged è¨ˆæ•¸\n",
        "total_correct = 0\n",
        "total_preds = 0\n",
        "total_labels = 0\n",
        "\n",
        "# æ¯ä¸€ç­†çš„ y_true / y_predï¼ˆfor macro æŒ‡æ¨™ï¼‰\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels, img_names in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > threshold).float()\n",
        "\n",
        "        # ç´¯ç©æ¯ä¸€é¡çš„æº–ç¢ºæ•¸\n",
        "        correct_per_class += ((preds == labels) * labels).sum(dim=0).cpu()\n",
        "        total_per_class += labels.sum(dim=0).cpu()\n",
        "\n",
        "        # Micro-averaged è¨ˆæ•¸\n",
        "        total_correct += (preds * labels).sum().item()\n",
        "        total_preds += preds.sum().item()\n",
        "        total_labels += labels.sum().item()\n",
        "\n",
        "        # æ”¶é›†æ‰€æœ‰ prediction & labelï¼ˆfor macroï¼‰\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "        # å„²å­˜é æ¸¬çµæœï¼ˆfor è¼¸å‡º CSVï¼‰\n",
        "        for name, pred in zip(img_names, preds.cpu()):\n",
        "            label_indices = [str(i) for i, val in enumerate(pred) if val == 1]\n",
        "            results.append({'image_name': name, 'labels': ' '.join(label_indices)})\n",
        "\n",
        "# === æŒ‡æ¨™è¨ˆç®— ===\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# Macro æŒ‡æ¨™\n",
        "macro_precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "macro_recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "# Micro æŒ‡æ¨™\n",
        "precision = total_correct / (total_preds + 1e-8)\n",
        "recall = total_correct / (total_labels + 1e-8)\n",
        "f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "# Per-label Accuracy\n",
        "per_label_accuracy = (correct_per_class / (total_per_class + 1e-8))\n",
        "\n",
        "print(\"ğŸ“Š Evaluation Results\")\n",
        "print(f\"ğŸ¯ Micro:\")\n",
        "print(f\"  - Precision: {precision:.4f}\")\n",
        "print(f\"  - Recall:    {recall:.4f}\")\n",
        "print(f\"  - F1-score:  {f1:.4f}\")\n",
        "print(f\"\\nğŸ¯ Macro:\")\n",
        "print(f\"  - Precision: {macro_precision:.4f}\")\n",
        "print(f\"  - Recall:    {macro_recall:.4f}\")\n",
        "print(f\"  - F1-score:  {macro_f1:.4f}\")\n",
        "print(f\"\\nğŸ¯ Per-label Accuracy (mean): {per_label_accuracy.mean().item():.4f}\\n\")\n",
        "\n",
        "for i, acc in enumerate(per_label_accuracy):\n",
        "    print(f\"  - Label {i}: Accuracy = {acc.item():.4f}\")\n",
        "\n",
        "# å„²å­˜é æ¸¬çµæœ CSV\n",
        "output_csv = '/content/test_predictions.csv'\n",
        "pd.DataFrame(results).to_csv(output_csv, index=False)\n",
        "print(f\"\\nâœ… Prediction CSV saved to {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k5yqRfaCHKF",
        "outputId": "f7bfe747-9fd0-4585-909d-d1485f68dbaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Test CSV saved to /content/image_classification_data/test_labels.csv\n",
            "ğŸ“Š Evaluation Results\n",
            "ğŸ¯ Micro:\n",
            "  - Precision: 0.8218\n",
            "  - Recall:    0.7238\n",
            "  - F1-score:  0.7697\n",
            "\n",
            "ğŸ¯ Macro:\n",
            "  - Precision: 0.8297\n",
            "  - Recall:    0.6743\n",
            "  - F1-score:  0.7348\n",
            "\n",
            "ğŸ¯ Per-label Accuracy (mean): 0.6743\n",
            "\n",
            "  - Label 0: Accuracy = 0.7901\n",
            "  - Label 1: Accuracy = 0.7111\n",
            "  - Label 2: Accuracy = 0.7073\n",
            "  - Label 3: Accuracy = 0.5000\n",
            "  - Label 4: Accuracy = 0.7059\n",
            "  - Label 5: Accuracy = 0.4500\n",
            "  - Label 6: Accuracy = 0.8554\n",
            "\n",
            "âœ… Prediction CSV saved to /content/test_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}