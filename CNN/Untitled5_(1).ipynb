{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTh0_NnmrSS5",
        "outputId": "9b84478e-7c88-413b-be2d-9f252ee67ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/dataset_all.zip'\n",
        "extract_path = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "PnERq2mvsYzC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 原始路徑\n",
        "base_input_path = '/content/data/dataset_all'  # 改成你解壓縮後的根目錄\n",
        "base_output_path = '/content/image_classification_data'\n",
        "\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "for split in splits:\n",
        "    image_dir = os.path.join(base_input_path, split, 'images')\n",
        "    label_dir = os.path.join(base_input_path, split, 'labels')\n",
        "    output_split_dir = os.path.join(base_output_path, split)\n",
        "\n",
        "    os.makedirs(output_split_dir, exist_ok=True)\n",
        "\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith('.txt'):\n",
        "            continue\n",
        "\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if not lines:\n",
        "                continue\n",
        "            class_id = lines[0].split()[0]  # YOLO 格式的第一個欄位是類別\n",
        "\n",
        "        image_name = label_file.replace('.txt', '.jpg')  # 或 .png，根據你的檔名決定\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            continue\n",
        "\n",
        "        class_dir = os.path.join(output_split_dir, class_id)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        shutil.copy(image_path, os.path.join(class_dir, image_name))\n"
      ],
      "metadata": {
        "id": "5uolasCvtC_t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def create_multilabel_csv(image_dir, label_dir, output_csv):\n",
        "    data = []\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith('.txt'):\n",
        "            continue\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if len(lines) == 0:\n",
        "                continue\n",
        "            # 擷取每一行的 class_id，放進集合避免重複\n",
        "            classes = set()\n",
        "            for line in lines:\n",
        "                class_id = line.split()[0]\n",
        "                classes.add(class_id)\n",
        "        image_name = label_file.replace('.txt', '.jpg')  # 或改成你用的副檔名\n",
        "        data.append({'image_name': image_name, 'labels': ' '.join(sorted(classes))})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Saved multilabel CSV to {output_csv}\")\n",
        "\n",
        "# 範例路徑，改成你實際路徑\n",
        "train_img_dir = '/content/data/dataset_all/train/images'\n",
        "train_label_dir = '/content/data/dataset_all/train/labels'\n",
        "val_img_dir = '/content/data/dataset_all/val/images'\n",
        "val_label_dir = '/content/data/dataset_all/val/labels'\n",
        "\n",
        "# 產生CSV\n",
        "create_multilabel_csv(train_img_dir, train_label_dir, '/content/image_classification_data/train_labels.csv')\n",
        "create_multilabel_csv(val_img_dir, val_label_dir, '/content/image_classification_data/val_labels.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy9WtkDT7Ssp",
        "outputId": "a68686d6-6cdd-4352-dab8-9cf11bcede98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved multilabel CSV to /content/image_classification_data/train_labels.csv\n",
            "Saved multilabel CSV to /content/image_classification_data/val_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. 自訂 Dataset\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_path, img_dir, num_classes, transform=None):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.img_dir = img_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['image_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        labels = row['labels'].split()  # 假設 labels 是以空白隔開的多標籤字串\n",
        "        multi_hot = torch.zeros(self.num_classes, dtype=torch.float32)\n",
        "        for l in labels:\n",
        "            multi_hot[int(l)] = 1.0\n",
        "\n",
        "        return image, multi_hot\n",
        "\n",
        "# 2. 設定參數\n",
        "num_classes = 7  # 你的類別數量，請修改\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "train_csv = '/content/image_classification_data/train_labels.csv'\n",
        "val_csv = '/content/image_classification_data/val_labels.csv'\n",
        "train_dir = '/content/data/dataset_all/train/images'\n",
        "val_dir = '/content/data/dataset_all/val/images'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],  # 這是ResNet常用的ImageNet正規化\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 3. 建立 Dataset 與 DataLoader\n",
        "train_dataset = MultiLabelDataset(train_csv, train_dir, num_classes, transform=transform)\n",
        "val_dataset = MultiLabelDataset(val_csv, val_dir, num_classes, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# 4. 建立模型\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        # 🔍 動態推算 Flatten size\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
        "            dummy_output = self.features(dummy_input)\n",
        "            self.flattened_size = dummy_output.view(1, -1).shape[1]  # e.g. 128 * 28 * 28\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.flattened_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "\n",
        "# 5. 損失函數和優化器\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# 6. 訓練與驗證函式\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    return running_loss / len(train_dataset)\n",
        "\n",
        "def validate():\n",
        "    model.eval()\n",
        "    threshold = 0.5\n",
        "    correct_per_class = torch.zeros(num_classes)\n",
        "    total_per_class = torch.zeros(num_classes)\n",
        "\n",
        "    total_correct = 0\n",
        "    total_preds = 0\n",
        "    total_labels = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = (torch.sigmoid(outputs) > threshold).float()\n",
        "\n",
        "            # per-class 正確數與總數\n",
        "            correct_per_class += ((preds == labels) * labels).sum(dim=0).cpu()\n",
        "            total_per_class += labels.sum(dim=0).cpu()\n",
        "\n",
        "            # micro F1 所需的統計\n",
        "            total_correct += (preds * labels).sum().item()\n",
        "            total_preds += preds.sum().item()\n",
        "            total_labels += labels.sum().item()\n",
        "\n",
        "    # per-label accuracy\n",
        "    per_label_accuracy = (correct_per_class / (total_per_class + 1e-8)).mean().item()\n",
        "\n",
        "    # micro-average F1\n",
        "    precision = total_correct / (total_preds + 1e-8)\n",
        "    recall = total_correct / (total_labels + 1e-8)\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.0\n",
        "\n",
        "    return per_label_accuracy, precision, recall, f1\n",
        "\n",
        "# 7. 主訓練迴圈\n",
        "best_accuracy = 0.0  # 初始化最佳 accuracy\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_one_epoch()\n",
        "    per_label_accuracy, precision, recall, f1 = validate()\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Per-label Accuracy={per_label_accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    # 只保留最佳模型\n",
        "    if per_label_accuracy > best_accuracy:\n",
        "        best_accuracy = per_label_accuracy\n",
        "        save_path = \"best_model.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Best model updated and saved with accuracy: {best_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWYOdAe56y0Q",
        "outputId": "561298c9-1ff9-4098-d8d5-bbd6ea00b58a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=0.5601, Per-label Accuracy=0.0880, Precision=0.4937, Recall=0.1193, F1=0.1921\n",
            "Best model updated and saved with accuracy: 0.0880\n",
            "Epoch 2: Train Loss=0.3606, Per-label Accuracy=0.2362, Precision=0.6467, Recall=0.3303, F1=0.4372\n",
            "Best model updated and saved with accuracy: 0.2362\n",
            "Epoch 3: Train Loss=0.2964, Per-label Accuracy=0.2950, Precision=0.7562, Recall=0.3700, F1=0.4969\n",
            "Best model updated and saved with accuracy: 0.2950\n",
            "Epoch 4: Train Loss=0.2460, Per-label Accuracy=0.4694, Precision=0.7733, Recall=0.5321, F1=0.6304\n",
            "Best model updated and saved with accuracy: 0.4694\n",
            "Epoch 5: Train Loss=0.1867, Per-label Accuracy=0.5445, Precision=0.8032, Recall=0.6116, F1=0.6944\n",
            "Best model updated and saved with accuracy: 0.5445\n",
            "Epoch 6: Train Loss=0.1346, Per-label Accuracy=0.6644, Precision=0.8156, Recall=0.7034, F1=0.7553\n",
            "Best model updated and saved with accuracy: 0.6644\n",
            "Epoch 7: Train Loss=0.1031, Per-label Accuracy=0.6611, Precision=0.8221, Recall=0.7064, F1=0.7599\n",
            "Epoch 8: Train Loss=0.0706, Per-label Accuracy=0.7015, Precision=0.8351, Recall=0.7278, F1=0.7778\n",
            "Best model updated and saved with accuracy: 0.7015\n",
            "Epoch 9: Train Loss=0.0594, Per-label Accuracy=0.7185, Precision=0.8311, Recall=0.7523, F1=0.7897\n",
            "Best model updated and saved with accuracy: 0.7185\n",
            "Epoch 10: Train Loss=0.0417, Per-label Accuracy=0.6762, Precision=0.8246, Recall=0.7187, F1=0.7680\n",
            "Epoch 11: Train Loss=0.0329, Per-label Accuracy=0.7086, Precision=0.8357, Recall=0.7309, F1=0.7798\n",
            "Epoch 12: Train Loss=0.0345, Per-label Accuracy=0.6538, Precision=0.8156, Recall=0.7034, F1=0.7553\n",
            "Epoch 13: Train Loss=0.0289, Per-label Accuracy=0.6941, Precision=0.8375, Recall=0.7248, F1=0.7770\n",
            "Epoch 14: Train Loss=0.0193, Per-label Accuracy=0.7119, Precision=0.8243, Recall=0.7462, F1=0.7833\n",
            "Epoch 15: Train Loss=0.0177, Per-label Accuracy=0.7062, Precision=0.7980, Recall=0.7492, F1=0.7729\n",
            "Epoch 16: Train Loss=0.0148, Per-label Accuracy=0.7032, Precision=0.8094, Recall=0.7401, F1=0.7732\n",
            "Epoch 17: Train Loss=0.0155, Per-label Accuracy=0.7116, Precision=0.8288, Recall=0.7401, F1=0.7819\n",
            "Epoch 18: Train Loss=0.0138, Per-label Accuracy=0.6991, Precision=0.8417, Recall=0.7156, F1=0.7736\n",
            "Epoch 19: Train Loss=0.0185, Per-label Accuracy=0.7098, Precision=0.8556, Recall=0.7248, F1=0.7848\n",
            "Epoch 20: Train Loss=0.0123, Per-label Accuracy=0.7087, Precision=0.8587, Recall=0.7431, F1=0.7967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 儲存模型\n",
        "torch.save(model.state_dict(), '20epochs_model_weights.pth')\n"
      ],
      "metadata": {
        "id": "RKRjgtW5Am5x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "\n",
        "# === 1. 建立 test CSV（從 label 檔推得 image 名）===\n",
        "def create_multilabel_csv(image_dir, label_dir, output_csv):\n",
        "    data = []\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith('.txt'):\n",
        "            continue\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if len(lines) == 0:\n",
        "                continue\n",
        "            classes = set()\n",
        "            for line in lines:\n",
        "                class_id = line.split()[0]\n",
        "                classes.add(class_id)\n",
        "        image_name = label_file.replace('.txt', '.jpg')  # 確認副檔名是否正確\n",
        "        data.append({'image_name': image_name, 'labels': ' '.join(sorted(classes))})\n",
        "\n",
        "    pd.DataFrame(data).to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Test CSV saved to {output_csv}\")\n",
        "\n",
        "# === 2. 自訂 Dataset 類 ===\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_path, img_dir, num_classes, transform=None):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.img_dir = img_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['image_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        labels = row['labels'].split()\n",
        "        multi_hot = torch.zeros(self.num_classes, dtype=torch.float32)\n",
        "        for l in labels:\n",
        "            multi_hot[int(l)] = 1.0\n",
        "\n",
        "        return image, multi_hot, row['image_name']\n",
        "\n",
        "# === 3. 資料與模型設定 ===\n",
        "num_classes = 7\n",
        "test_img_dir = '/content/data/dataset_all/test/images'\n",
        "test_label_dir = '/content/data/dataset_all/test/labels'\n",
        "test_csv_path = '/content/image_classification_data/test_labels.csv'\n",
        "create_multilabel_csv(test_img_dir, test_label_dir, test_csv_path)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === 4. 載入模型 ===\n",
        "model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "# === 5. 測試與評估 ===\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "test_dataset = MultiLabelDataset(test_csv_path, test_img_dir, num_classes, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "threshold = 0.5\n",
        "results = []\n",
        "\n",
        "correct_per_class = torch.zeros(num_classes)\n",
        "total_per_class = torch.zeros(num_classes)\n",
        "\n",
        "# Micro-averaged 計數\n",
        "total_correct = 0\n",
        "total_preds = 0\n",
        "total_labels = 0\n",
        "\n",
        "# 每一筆的 y_true / y_pred（for macro 指標）\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels, img_names in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > threshold).float()\n",
        "\n",
        "        # 累積每一類的準確數\n",
        "        correct_per_class += ((preds == labels) * labels).sum(dim=0).cpu()\n",
        "        total_per_class += labels.sum(dim=0).cpu()\n",
        "\n",
        "        # Micro-averaged 計數\n",
        "        total_correct += (preds * labels).sum().item()\n",
        "        total_preds += preds.sum().item()\n",
        "        total_labels += labels.sum().item()\n",
        "\n",
        "        # 收集所有 prediction & label（for macro）\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "        # 儲存預測結果（for 輸出 CSV）\n",
        "        for name, pred in zip(img_names, preds.cpu()):\n",
        "            label_indices = [str(i) for i, val in enumerate(pred) if val == 1]\n",
        "            results.append({'image_name': name, 'labels': ' '.join(label_indices)})\n",
        "\n",
        "# === 指標計算 ===\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# Macro 指標\n",
        "macro_precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "macro_recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "# Micro 指標\n",
        "precision = total_correct / (total_preds + 1e-8)\n",
        "recall = total_correct / (total_labels + 1e-8)\n",
        "f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "# Per-label Accuracy\n",
        "per_label_accuracy = (correct_per_class / (total_per_class + 1e-8))\n",
        "\n",
        "print(\"📊 Evaluation Results\")\n",
        "print(f\"🎯 Micro:\")\n",
        "print(f\"  - Precision: {precision:.4f}\")\n",
        "print(f\"  - Recall:    {recall:.4f}\")\n",
        "print(f\"  - F1-score:  {f1:.4f}\")\n",
        "print(f\"\\n🎯 Macro:\")\n",
        "print(f\"  - Precision: {macro_precision:.4f}\")\n",
        "print(f\"  - Recall:    {macro_recall:.4f}\")\n",
        "print(f\"  - F1-score:  {macro_f1:.4f}\")\n",
        "print(f\"\\n🎯 Per-label Accuracy (mean): {per_label_accuracy.mean().item():.4f}\\n\")\n",
        "\n",
        "for i, acc in enumerate(per_label_accuracy):\n",
        "    print(f\"  - Label {i}: Accuracy = {acc.item():.4f}\")\n",
        "\n",
        "# 儲存預測結果 CSV\n",
        "output_csv = '/content/test_predictions.csv'\n",
        "pd.DataFrame(results).to_csv(output_csv, index=False)\n",
        "print(f\"\\n✅ Prediction CSV saved to {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k5yqRfaCHKF",
        "outputId": "f7bfe747-9fd0-4585-909d-d1485f68dbaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test CSV saved to /content/image_classification_data/test_labels.csv\n",
            "📊 Evaluation Results\n",
            "🎯 Micro:\n",
            "  - Precision: 0.8218\n",
            "  - Recall:    0.7238\n",
            "  - F1-score:  0.7697\n",
            "\n",
            "🎯 Macro:\n",
            "  - Precision: 0.8297\n",
            "  - Recall:    0.6743\n",
            "  - F1-score:  0.7348\n",
            "\n",
            "🎯 Per-label Accuracy (mean): 0.6743\n",
            "\n",
            "  - Label 0: Accuracy = 0.7901\n",
            "  - Label 1: Accuracy = 0.7111\n",
            "  - Label 2: Accuracy = 0.7073\n",
            "  - Label 3: Accuracy = 0.5000\n",
            "  - Label 4: Accuracy = 0.7059\n",
            "  - Label 5: Accuracy = 0.4500\n",
            "  - Label 6: Accuracy = 0.8554\n",
            "\n",
            "✅ Prediction CSV saved to /content/test_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}